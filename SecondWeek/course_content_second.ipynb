{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "With Pandas (= panel data), tabular data can be handled very conveniently. More at https://pandas.pydata.org/.\n",
    "\n",
    "Very helpful:\n",
    "- https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html\n",
    "- https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\n",
    "\n",
    "Pandas uses two important data structures:\n",
    "- `Series` are 1-dimensional arrays. In contrast to Numpy arrays, however, they have an additional index that can be used to conveniently access entries. Internally, this is based on Numpy arrays.\n",
    "- `DataFrame` is an entire table consisting of several series (=columns) of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # empfehlenswerte Konvention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every column is a `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column of a DataFrame (or series) is the so-called index. It contains the *row names*. By default, these are the numbers 0, 1, 2, ...\n",
    "However, you can also set a different index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man kann eine Series auch explizit erzeugen. Falls man keinen Index angibt, sind es wieder die Zahlen 0, 1, 2, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and write data\n",
    "\n",
    "Pandas offers a variety of options for reading data from databases (via SQL) or from files, e.g. csv, xlsx, parquet, arrow, feather, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gain initial insight into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading and writing xlsx files is also no problem. Here is an example of saving the data set as xlsx. The *openpyxl* package must be installed for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection of columns or rows\n",
    "\n",
    "If you select not just one column name but a list of several columns, you get a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When selecting rows, you usually want to select rows that fulfill certain properties.\n",
    "To do this, write a true/false vector of the length of the DataFrame in the square brackets `[]`.\n",
    "Comparison operators (`<`, `>`, `==`, `<=`, `>=`, `!=`) and Boolean operators `&` (and), `|` (or) and `~` (not) are often very helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to select certain rows and columns *in one step*, `.loc` and `.iloc` are suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `.loc[rows, columns]` (= location) you can address entries via their **row index**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create, remove and rename columns\n",
    "\n",
    "When calculating new columns, the power of vectorization becomes clear.\n",
    "The calculations are performed element by element for each entry of the vector.\n",
    "An explicit loop is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to perform complicated calculations, you can write a function and apply it line by line using `map()` or `apply()`. \n",
    "line by line. More on this later! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rename columns, pass a dictionary with entries of the form `{\"old_colname\": \"new_colname\"}` or a suitable string function to the `.rename` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization\n",
    "\n",
    "(Here only very briefly. Visualization gets an extra session)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the dataframe has consequences for the index. \n",
    "If you also want the index to be ordered, you can either reset the index or have it ignored directly during sorting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation of data\n",
    "\n",
    "Typical aggregation functions such as mean(), sum(), max(), quantile() ... can be called directly as a method of `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often you want to perform such aggregations in groups, i.e. for each unique value of a feature. This is known as **Split-Apply-Combine**: The overall table is split into individual tables according to the unique values of a feature, the aggregation function is calculated for each such table and then these values are collected in a smaller table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just used a square bracket with column names directly after `.groupby()`. This is often done and restricts the individual tables to the named columns. The aggregation function then only affects these columns.\n",
    "\n",
    "You can also group by several characteristics. The resulting object then has a MultiIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often you want to count how often a value occurs in a column. This provides the basis for bar charts.\n",
    "(Note: By default, NA values do not form a separate group and are not listed. However, this is often relevant in the context of data preparation. For this purpose, you can set the option `dropna=False` in `.groupby()` or `.value_counts()`).\n",
    "As the resulting object is not a DataFrame, a `.reset_index()` is suitable for making the index an explicit column and connecting sorting steps, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are both `.count()` and `.size()`. These are very similar. While `.size()` returns the number of rows, `.count()` returns the number of non-NA values. One function therefore counts NA values, while the other does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging (=joining) several tables\n",
    "\n",
    "Very often you want to combine several tables to enrich information.\n",
    "Pandas can also be used to combine several DataFrames, as in SQL.\n",
    "\n",
    "The following table shows the development of student numbers for the TH Aschaffenburg.\n",
    "Unfortunately, only the course abbreviations are included and there is also no assignment to faculties.\n",
    "The second table provides this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `merge()` you can perform all kinds of JOIN operations in Pandas, as we know them from SQL.\n",
    "Here we want to enrich the table *th_small* with the respective degree program information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `merge()` you can also perform other joins (RIGHT JOIN, INNER JOIN, OUTER JOIN), for example by specifying `how=\"outer\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to combine two DataFrames is to simply append one to the other.\n",
    "Of course, this only makes sense if the columns match (or are at least subsets of each other).\n",
    "For example, let's look at the data for the degree programs *MEDS* and *SD*.\n",
    "With `concat()`, the two tables can be appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data wrangling for advanced users: Long format and wide format\n",
    "\n",
    "<!--- Data source:\n",
    "- Destatis, Table 12411-0015: Population: districts, reference date (selection: all reference dates). (Download flat file!)\n",
    "- Destatis, Table 12411-0018: Population: districts, reference date, sex, age groups (selection: all reference dates but only the 3 districts of Aschaffenburg, Würzburg and Schweinfurt). (Download Flat-File!) -->\n",
    "\n",
    "There are various ways of displaying the same data in tabular form.\n",
    "Depending on the application, it is necessary to switch between these forms. This is sometimes known as “pivoting”.\n",
    "The best way to see this is with an example. \n",
    "\n",
    "<!--- The following table (adapted from Destatis table 12411-0016) shows the population development of the three cities Aschaffenburg, Schweinfurt and Würzburg.-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity, we will initially disregard the total number of students and limit ourselves to the degree programs *BW* (Business Administration), *SD* (Software Design) and *EIT* (Electrical Engineering and Information Technology) since the winter semester 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above contains one row for each combination of academic year and subject. \n",
    "This is called **long format**.\n",
    "For time series in particular, however, it is often clearer to arrange the data differently.\n",
    "In this case, we want to display the enrolment figures for each subject in a separate column.\n",
    "This is then the **wide format**.\n",
    "\n",
    "With the function `pivot()` you can “rotate” the fields appropriately.\n",
    "Here you must specify which columns are to be retained as an index, which column contains the new column names and which are the actual values.\n",
    "The wide format may seem clearer, but has the disadvantage that you have to change the table schema when new study programs are added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can also convert from wide format to long format.\n",
    "This works with `melt()`.\n",
    "(First, however, we use `reset_index()` to make the index a regular column).\n",
    "In the argument `id_vars` we list all columns that are to be kept constant - all other columns are \"pivoted\" to two new columns, in that each combination of column name and respective entry forms a new line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had just restricted the data set to the number of freshmen and removed the *students* column.\n",
    "So we only let `pivot()` pivot the column *freshmen*.\n",
    "\n",
    "If, on the other hand, we leave the student numbers in the data set, we can also pivot them.\n",
    "This results in a **MultiIndex** for the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closely related to `pivot()` and `melt()` are the `stack()` and `unstack()` functions.\n",
    "They are particularly useful in combination with indexes and MultiIndexes.\n",
    "\n",
    "- `stack()` pivots all column labels (except the index) and returns a series (or a DataFrame) with an additional inner index level.\n",
    "- `unstack()` pivots the innermost index level to column labels and thus creates a DataFrame.\n",
    "\n",
    "For the sake of clarity, let's restrict ourselves to the beginner numbers above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`stack()` rotates all column names to a new inner index level and thus returns a series with a two-level multi-index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `unstack()`, the innermost level of a MultiIndex becomes new column names and we get the original DataFrame again.\n",
    "(If you want to pivot another index level instead of the innermost level, you can specify an index level using both `stack` and `unstack`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way: Instead of calling `pivot` you can also use `set_index` to create a MultiIndex and then call `unstack`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FoDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
